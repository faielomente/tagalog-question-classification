{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing_csr\n",
    "import collections\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class treeNode:\n",
    "    \"\"\"variables:\n",
    "    name of the node, a count\n",
    "    nodelink used to link similar items\n",
    "    parent vaiable used to refer to the parent of the node in the tree\n",
    "    node contains an empty dictionary for the children in the node\"\"\"\n",
    "    \n",
    "    def __init__(self, nameValue, numOccur, parentNode):\n",
    "        self.name = nameValue\n",
    "        self.count = numOccur\n",
    "        self.nodeLink = None\n",
    "        self.parent = parentNode      #needs to be updated\n",
    "        self.children = []\n",
    "\n",
    "# get the child of this node with the name 'name'\n",
    "    def get_child(self, name):\n",
    "        for c in self.children:\n",
    "            if c.name == name:\n",
    "                return c\n",
    "        \n",
    "        return None\n",
    "            \n",
    "#increments the count variable with a given amount    \n",
    "    def inc(self, numOccur):\n",
    "        self.count += numOccur\n",
    "\n",
    "#display tree in text. Useful for debugging        \n",
    "    def disp(self, ind=1):\n",
    "        print ('  '*ind, self.name, self.count)\n",
    "        \n",
    "        for child in self.children:\n",
    "            child.disp(ind+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Testin the Tree Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# testing the tree\n",
    "# rootNode = treeNode('pyramid',9,None)\n",
    "# rootNode.children.append(treeNode('eye',13,None))\n",
    "# rootNode.disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Building the FP-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def updateHeader(nodeToTest, targetNode): \n",
    "    \"\"\"This version does not use recursion.\"\"\"\n",
    "    \n",
    "    # Do not use recursion to traverse a linked list!\n",
    "    while (nodeToTest.nodeLink != None): \n",
    "        nodeToTest = nodeToTest.nodeLink\n",
    "    \n",
    "    nodeToTest.nodeLink = targetNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def updateTree(items, inTree, headerTable, count):\n",
    "    \"\"\"grow the Fp-tree with an itemset\"\"\"\n",
    "    \n",
    "    # check if items[0] in retTree.children\n",
    "    if inTree.get_child(items[0]) != None: \n",
    "        inTree.get_child(items[0]).inc(count)\n",
    "    \n",
    "    else:   #add items[0] to inTree.children\n",
    "        inTree.children.append(treeNode(items[0], count, inTree))\n",
    "        \n",
    "        if headerTable[items[0]] == None: #update header table \n",
    "            #W A R N I N G!\n",
    "            headerTable[items[0]] = inTree.children[\n",
    "                len(inTree.children)-1] \n",
    "        else:\n",
    "            updateHeader(headerTable[items[0]], \n",
    "                         inTree.children[len(inTree.children)-1])\n",
    "    \n",
    "    if len(items) > 1: #call updateTree() with remaining ordered items\n",
    "        updateTree(items[1::], inTree.get_child(items[0]), \n",
    "                   headerTable, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def createTree(dataSet): #create FP-tree from dataset but don't mine\n",
    "    \"\"\"takes the dataset and the minimum support as arguments and \n",
    "    builds the FP-tree. This makes two passes through the dataset. \n",
    "    The first pass goes through everything in the dataset and counts \n",
    "    the frequency of each term. These are stored in the header table.\"\"\"\n",
    "    \n",
    "    headerTable = {}   \n",
    "#     print 'dataset: ',len(dataSet)\n",
    "    \n",
    "    #go over dataSet twice\n",
    "    for trans in dataSet:   #first pass counts frequency of occurance\n",
    "        for item in trans:\n",
    "            headerTable[item] = None\n",
    "    \n",
    "#     print 'headerTable: ',headerTable\n",
    "\n",
    "    itemSet = list(headerTable.keys())\n",
    "#     print 'itemSet: ',itemSet\n",
    "    \n",
    "    for k in headerTable: # reformat headerTable to use Node link \n",
    "        headerTable[k] = None\n",
    "    \n",
    "#     print 'headerTable: ',headerTable\n",
    "\n",
    "    retTree = treeNode('Null Set', 1, None) #create tree\n",
    "    \n",
    "    # dataSet.items() returns key-value tuple\n",
    "    for tranSet, count in dataSet.items():  #go through dataset 2nd time\n",
    "            items = list(tranSet)\n",
    "            # populate tree with ordered freq itemset\n",
    "            updateTree(items, retTree, headerTable, count)\n",
    "            \n",
    "#     print 'headerTable: ',headerTable\n",
    "\n",
    "    return retTree, headerTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadSimpDat():\n",
    "    \"\"\"Get the data from preprocessing.\"\"\"\n",
    "    \n",
    "    training, testing = preprocessing_csr.format(1)\n",
    "#     simpDat = [['saan', 'pr', 'vb', 'abbreviation'], \n",
    "#                ['paano', 'pr', 'vb', 'dt', 'dt', 'nn', 'cc', 'pr', 'abbreviation'], \n",
    "#                ['ano', 'dt', 'nn', 'vb', 'cc', 'nn', 'pr', 'vb', 'nn', 'abbreviation'],\n",
    "#                ['ano', 'pr', 'description'], \n",
    "#                ['anong', 'nn', 'pr', 'description'], \n",
    "#                ['bakit', 'dt', 'nn', 'pr', 'description'],\n",
    "#                ['sino', 'rb', 'pr', 'entity'], \n",
    "#                ['alin', 'cc', 'cd', 'dt', 'vb', 'pr', 'entity'], \n",
    "#                ['alin', 'rb', 'pr', 'dt', 'nn', 'pr', 'entity'],\n",
    "#                ['alin', 'dt', 'vb', 'entity'], \n",
    "#                ['sino', 'dt', 'nn', 'cc', 'nn', 'pr', 'human'], \n",
    "#                ['sino', 'rb', 'pr', 'human'], \n",
    "#                ['alin', 'cc', 'nn', 'dt', 'vb', 'pr', 'human'],\n",
    "#                ['saan', 'rb', 'pr', 'rb', 'location'], \n",
    "#                ['saan', 'pr', 'rb', 'location'], \n",
    "#                ['nasaan', 'pr', 'rb', 'rb', 'location'],\n",
    "#                ['kailan', 'rb', 'pr', 'vb', 'numeric'], \n",
    "#                ['kailan', 'pr', 'nn', 'cc', 'vb', 'vb', 'nn', 'numeric'], \n",
    "#                ['kailan', 'pr', 'vb', 'vb', 'numeric'], \n",
    "#                ['alin', 'cc', 'pr', 'cc', 'vb', 'cc', 'nn', 'dt', 'nn', 'pr', 'numeric'], \n",
    "#                ['ano', 'dt', 'nn', 'pr', 'vb', 'numeric'], \n",
    "#                ['paano', 'pr', 'vb', 'dt', 'dt', 'nn', 'cc', 'pr', 'abbreviation'], \n",
    "#                ['ano', 'dt', 'nn', 'vb', 'cc', 'nn', 'pr', 'vb', 'nn', 'abbreviation'],\n",
    "#                ['ano', 'pr', 'description'], \n",
    "#                ['anong', 'nn', 'pr', 'description'], \n",
    "#                ['bakit', 'dt', 'nn', 'pr', 'description'],\n",
    "#                ['sino', 'rb', 'pr', 'entity'], \n",
    "#                ['alin', 'cc', 'cd', 'dt', 'vb', 'pr', 'entity'], \n",
    "#                ['alin', 'rb', 'pr', 'dt', 'nn', 'pr', 'entity'],\n",
    "#     ]\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def createInitSet(dataSet):\n",
    "    \"\"\"the createTree() function doesnt take the input data as lists. \n",
    "    It expectsa a dictionary with the itemsets as the dictionary keys \n",
    "    and the frequency as the value. A createInitSet() function does \n",
    "    this conversion for you.\"\"\"\n",
    "\n",
    "    retDict = collections.OrderedDict()\n",
    "\n",
    "    for trans in dataSet:\n",
    "        if tuple(trans) in retDict:\n",
    "            retDict[tuple(trans)] += 1\n",
    "        else:\n",
    "            retDict[tuple(trans)] = 1\n",
    "\n",
    "    return retDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Testing the FP-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2462\n",
      "616\n"
     ]
    }
   ],
   "source": [
    "#testing the sample data\n",
    "training, testing = loadSimpDat()\n",
    "# print 'Training Data for Fp-growth algoithm:\\n',training\n",
    "print len(training)\n",
    "# print '\\nTesting Data: ',testing\n",
    "print len(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1363\n"
     ]
    }
   ],
   "source": [
    "initSet = createInitSet(training)\n",
    "# print initSet\n",
    "print '\\n', len(initSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#The FP-tree\n",
    "myFPtree, myHeaderTab = createTree(initSet)\n",
    "# print myHeaderTab\n",
    "# myFPtree.disp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## -----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Mine rules from the FP-tree and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ascendTreeV2(leafNode, prefixPath):\n",
    "    \"\"\" Ascends from leaf node to root, collecting the names of \n",
    "    items it encounters\"\"\"\n",
    "\n",
    "    if leafNode.parent != None:\n",
    "        prefixPath.append((leafNode.name, leafNode.count,))\n",
    "        ascendTreeV2(leafNode.parent, prefixPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#treeNode comes from header table\n",
    "def findPrefixPathV2(basePat, treeNode):\n",
    "    \"\"\"This function iterates through the linked list until it hits \n",
    "    the end. For each item it encounters, it calls ascendTree().\n",
    "    This list is returned and added to the conditional category base \n",
    "    dictionary called condPats.\"\"\"\n",
    "\n",
    "    condPats = [] #list of all the paths with each category has\n",
    "    \n",
    "    while treeNode != None:\n",
    "        prefixPath = []\n",
    "        ascendTreeV2(treeNode, prefixPath)\n",
    "#         print \"prefixPath: \",  prefixPath\n",
    "        condPats.append(list(reversed(list(prefixPath[1:]))))\n",
    "            \n",
    "        treeNode = treeNode.nodeLink\n",
    "        \n",
    "    return condPats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def csrMining(headerTable, minSup):\n",
    "    \n",
    "    suffixes = ['entity', 'abbreviation', 'description', 'human', \n",
    "                'location', 'numeric']\n",
    "    minedRules = []\n",
    "    \n",
    "    for i in range(0, len(suffixes)):\n",
    "        condPattBases = findPrefixPathV2(suffixes[i], \n",
    "                                         headerTable[suffixes[i]])\n",
    "        \n",
    "#         print 'Conditional category Bases for: ' ,suffixes[i],\n",
    "#         len(condPattBases), '\\n', condPattBases\n",
    "        \n",
    "        condFpTree = []\n",
    "        \n",
    "        for p in range(0, len(condPattBases)):\n",
    "            counts = [v[1] for v in condPattBases[p]]\n",
    "            \n",
    "            for q in range(0, len(counts)):\n",
    "                if counts[q] < minSup:\n",
    "                    break\n",
    "                elif q == len(counts)-1:\n",
    "                    condFpTree.append(condPattBases[p])\n",
    "#                     element = tuple(t[0] for t in condPattBases[p])\n",
    "#                     minedRules.append((element, suffixes[i],))\n",
    "                    \n",
    "        print 'Conditional Fp-Tree for: ' ,suffixes[i], len(condFpTree)\n",
    "        print condFpTree\n",
    "        \n",
    "        # holds the frequent pattern of each suffix as array of tuples\n",
    "        value = []\n",
    "        \n",
    "        for category in condFpTree:\n",
    "            element = tuple(t[0] for t in category)\n",
    "            value.append(element)\n",
    "            \n",
    "        minedRules.append([suffixes[i], value])\n",
    "        \n",
    "    return minedRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Fp-Tree for:  entity 2\n",
      "[[('paano', 356), ('pr', 151), ('vb', 86)], [('ano', 322), ('dt', 244)]]\n",
      "Conditional Fp-Tree for:  abbreviation 1\n",
      "[[('saan', 338), ('pr', 192), ('vb', 120)]]\n",
      "Conditional Fp-Tree for:  description 9\n",
      "[[('paano', 356), ('pr', 151), ('vb', 86)], [('saan', 338), ('pr', 192), ('vb', 120)], [('ano', 322), ('dt', 244), ('nn', 115)], [('paano', 356), ('rb', 190)], [('kailan', 353), ('pr', 191), ('vb', 96)], [('saan', 338), ('pr', 192)], [('paano', 356), ('pr', 151)], [('ano', 322), ('dt', 244)], [('kailan', 353), ('pr', 191)]]\n",
      "Conditional Fp-Tree for:  human 2\n",
      "[[('paano', 356), ('pr', 151), ('vb', 86)], [('sino', 345), ('dt', 222), ('vb', 118)]]\n",
      "Conditional Fp-Tree for:  location 2\n",
      "[[('saan', 338), ('pr', 192), ('vb', 120)], [('saan', 338), ('pr', 192)]]\n",
      "Conditional Fp-Tree for:  numeric 3\n",
      "[[('saan', 338), ('pr', 192), ('vb', 120)], [('kailan', 353), ('pr', 191), ('vb', 96)], [('kailan', 353), ('rb', 109)]]\n"
     ]
    }
   ],
   "source": [
    "rules = csrMining(myHeaderTab, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## -------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Conflict Resolution Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def is_subset(rule, patt):\n",
    "    r = list(rule)\n",
    "    p = list(patt)\n",
    "    \n",
    "    if len(r) > len(p):\n",
    "        return False\n",
    "    else:\n",
    "        l = p[:len(r)]\n",
    "        if r == l:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getOrderedRuleSet(trainingData, rules):\n",
    "    \"\"\"Rank all of the mined rules according to their accuracy.\n",
    "    Form of both data: ((pattern), category)\n",
    "    Returns the oredered rule set as an array of tuples in the\n",
    "    form (((pattern), category), accuracy).\n",
    "    \"\"\"\n",
    "    \n",
    "    antCounts = {} # number of occurances of the antecedent\n",
    "    antConseqCounts = {}\n",
    "    \n",
    "    for r in rules: # populate dictionaries\n",
    "        for pattern in r[1]:\n",
    "            antCounts[pattern] = 0\n",
    "            antConseqCounts[(pattern, r[0])] = 0\n",
    "    \n",
    "    # count number of antecedent in training data\n",
    "    for data in trainingData: \n",
    "        if data[0] in antCounts:\n",
    "            antCounts[data[0]] += 1\n",
    "            \n",
    "#     print \"Antecedent Count Dictionary:\\n\", antCounts\n",
    "\n",
    "    # count number of antecedent matches with the consequent \n",
    "    # in training data\n",
    "    for data in trainingData:\n",
    "        if data in antConseqCounts:\n",
    "            antConseqCounts[data] += 1\n",
    "            \n",
    "#     print \"Antecendent Consequence:\\n\", antConseqCounts\n",
    "    \n",
    "    orderedRuleSet = []\n",
    "    for rule in antConseqCounts:\n",
    "        accuracy = (float(antConseqCounts[rule])/\n",
    "                    float(antCounts[rule[0]]))*100\n",
    "        accuracy = int(accuracy)\n",
    "        orderedRuleSet.append((rule, accuracy,))\n",
    "        \n",
    "    orderedRuleSet = sorted(orderedRuleSet, key=lambda rule: rule[1], \n",
    "                            reverse=True)\n",
    "    print \"Ordered Rule Set:\\n\", orderedRuleSet\n",
    "    \n",
    "    return orderedRuleSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getDefaultClass(testData):\n",
    "    \"\"\"Data form: ((pattern), category)\"\"\"\n",
    "    \n",
    "    questWord = {'alin': 'entity', 'saan':'location', 'ano':'entity', \n",
    "                 'kailan':'numeric', 'paano':'description', \n",
    "                 'sino':'human', 'bakit':'description'}\n",
    "    \n",
    "    for key in questWord:\n",
    "        if key in testData[0]:\n",
    "            return questWord[key]\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Classification and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def classify(testingData, rules, decisionList):\n",
    "    \"\"\"testingData form: ((pattern), category)\n",
    "    rules form: [['category', [(pattern1), (pattern2)]]]\n",
    "    decisionList form: [(((pattern), 'category'), accuracy)]\"\"\"\n",
    "\n",
    "    \n",
    "    table = []\n",
    "    \n",
    "    for data in testingData: # populate table\n",
    "        row = []\n",
    "        row.append(data[0])\n",
    "        \n",
    "        cat = []\n",
    "        for r in rules: # question classification\n",
    "            for category in r[1]:\n",
    "                if data[0] == category:\n",
    "                    cat.append(r[0])\n",
    "        \n",
    "        # Conflict Resolution\n",
    "        # if sentence structure did not trigger any category\n",
    "        if len(cat) == 0: \n",
    "            for i in range(0, len(rules)): # for each category\n",
    "                # for each pattern in that category\n",
    "                for j in range(0, len(rules[i][1])): \n",
    "                    # check if any rule is a subset of a sentence\n",
    "                    if is_subset(rules[i][1][j], data[0]) == True:\n",
    "                        cat.append(rules[i][0])\n",
    "                        break\n",
    "                    # if testing still didn't trigger any rule\n",
    "                    # assign default class according to its question word\n",
    "                    elif j == len(rules)-1 and is_subset(rules[i][1][j], \n",
    "                                                         data[0])==False:\n",
    "                        default = getDefaultClass(data[0])\n",
    "                        if default != None:\n",
    "                            cat.append(default)\n",
    "                            break\n",
    "            \n",
    "            # more than one category was triggered by the subset\n",
    "            if len(cat)>1:\n",
    "                default = getDefaultClass(data[0])\n",
    "                if default != None:\n",
    "                    cat = []\n",
    "                    cat.append(default)\n",
    "\n",
    "#   For debugging purpose:                  \n",
    "#             if len(cat) > 1:\n",
    "#                 print \"cat=0: \", data[0], cat\n",
    "        elif len(cat) > 1:\n",
    "            ranks = []\n",
    "            # for each category triggered by data\n",
    "            for i in range(0, len(cat)): \n",
    "                # combine data pattern with category as tuples\n",
    "                tmpD = (data[0], cat[i],) \n",
    "                \n",
    "                # for each rule in decisionList\n",
    "                for rule in decisionList:\n",
    "                    # if combined pattern and category match rule[i]\n",
    "                    if tmpD == rule[0]: \n",
    "                        # get the index\n",
    "                        ranks.append(decisionList.index(rule))\n",
    "#                         print ranks\n",
    "            \n",
    "            newCat = []\n",
    "            newCat.append(cat[ranks.index(max(ranks))])\n",
    "            cat = newCat\n",
    "            \n",
    "#           For debugging purpose:                  \n",
    "#             if len(cat):\n",
    "#                 print \"cat=1: \", data[0], cat\n",
    "            \n",
    "        row.append(cat)\n",
    "        table.append(row)\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def initTestingSet(testingSet):\n",
    "    retSet = []\n",
    "    \n",
    "    for data in testingSet:\n",
    "        key = tuple(data[:len(data)-2])\n",
    "        value = data[len(data)-1]\n",
    "        retSet.append((key,value,))\n",
    "    \n",
    "    return retSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def initTrainingData(trainingSet):\n",
    "    \"\"\"trainingSet form: ['anong', 'jj', 'pr', 'vb', 'cc', \n",
    "    'vb', 'pr', 'cc', 'pr', 'dt', 'vb', 'pr', 'description']\n",
    "    Returns retSet in the form: ((pattern), category)\"\"\"\n",
    "    \n",
    "    retSet = []\n",
    "    \n",
    "    for data in trainingSet:\n",
    "        lst = list(data)\n",
    "        pattern = tuple(lst[:len(lst)-1])\n",
    "        category = lst[len(lst)-1]\n",
    "        retSet.append((pattern, category,))\n",
    "            \n",
    "    return retSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testingData = initTestingSet(testing)\n",
    "trainingData = initTrainingData(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordered Rule Set:\n",
      "[((('kailan', 'rb'), 'numeric'), 100), ((('paano', 'pr'), 'description'), 100), ((('kailan', 'pr'), 'description'), 100), ((('paano', 'rb'), 'description'), 100), ((('sino', 'dt', 'vb'), 'human'), 100), ((('ano', 'dt', 'nn'), 'description'), 100), ((('paano', 'pr', 'vb'), 'description'), 87), ((('kailan', 'pr', 'vb'), 'numeric'), 75), ((('saan', 'pr', 'vb'), 'location'), 73), ((('saan', 'pr'), 'description'), 66), ((('ano', 'dt'), 'entity'), 50), ((('ano', 'dt'), 'description'), 50), ((('saan', 'pr'), 'location'), 33), ((('kailan', 'pr', 'vb'), 'description'), 24), ((('saan', 'pr', 'vb'), 'description'), 21), ((('paano', 'pr', 'vb'), 'human'), 6), ((('paano', 'pr', 'vb'), 'entity'), 6), ((('saan', 'pr', 'vb'), 'abbreviation'), 2), ((('saan', 'pr', 'vb'), 'numeric'), 2)]\n"
     ]
    }
   ],
   "source": [
    "decisionList = getOrderedRuleSet(trainingData, rules)\n",
    "predictionTable = classify(testingData, rules, decisionList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getComparisonTable(testingData, table):\n",
    "    perfTable = []\n",
    "    \n",
    "    for i in range(0, len(testingData)):\n",
    "        row = []\n",
    "        row.append(testingData[i][1])\n",
    "        row.append(table[i][1])\n",
    "        perfTable.append(row)\n",
    "    \n",
    "#     print perfTable\n",
    "    \n",
    "    correct = 0\n",
    "    misclassified = 0\n",
    "    unclassified = 0\n",
    "    multCat = 0\n",
    "    \n",
    "    for item in perfTable:\n",
    "        if len(item[1]) > 1:\n",
    "            multCat += 1\n",
    "        else:\n",
    "            if item[0] == item[1][0]:\n",
    "                correct += 1\n",
    "            elif len(item[1]) == 0:\n",
    "                unclassified += 1\n",
    "            elif item[0] != item[1][0]:\n",
    "                misclassified += 1\n",
    "            \n",
    "    print \"Total number of testing data: \", len(testingData)\n",
    "    print \"Correctly classified items: \", correct\n",
    "    print \"Misclassified items: \", misclassified\n",
    "    print \"Unclassified items: \", unclassified\n",
    "    print \"Mutiple Classified items: \", multCat\n",
    "    \n",
    "    return perfTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of testing data:  616\n",
      "Correctly classified items:  485\n",
      "Misclassified items:  131\n",
      "Unclassified items:  0\n",
      "Mutiple Classified items:  0\n"
     ]
    }
   ],
   "source": [
    "compTable = getComparisonTable(testingData, predictionTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6718109648670284, 0.70800870418986761, 0.67500777340633455, None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['abbreviation', 'entity', 'description', 'human', \n",
    "            'location', 'numeric']\n",
    "y_category = []\n",
    "y_pred = []\n",
    "\n",
    "for row in compTable:\n",
    "    y_category.append(row[0])\n",
    "    y_pred.append(row[1][0])\n",
    "\n",
    "precision_recall_fscore_support(y_category, y_pred, labels=categories, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.69172932,  0.77161863,  0.82608696,  0.95505618,\n",
       "        0.80555556])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate f-score for each category\n",
    "f1_score(y_category,y_pred, labels=categories, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78695511536841034"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate f-score of the classifier\n",
    "f1_score(y_category,y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   7,   0,   0,   2,   0],\n",
       "       [  0,  92,   0,   1,   0,   0],\n",
       "       [  0,  58, 174,  13,   1,  15],\n",
       "       [  0,  13,   4,  76,   1,   0],\n",
       "       [  0,   3,   0,   0,  85,   1],\n",
       "       [  0,   0,  12,   0,   0,  58]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row : actual :: column : predicted \n",
    "confusion_matrix(y_category,y_pred, labels=categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
