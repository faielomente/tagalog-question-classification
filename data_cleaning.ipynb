{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Data Cleaning\n",
    "\n",
    "**File:** `files/Help a CS Student Graduate.csv`  \n",
    "**Data format:** ```| Timestamp | Username | Ano | Bakit | Paano | Kailan | Sino | Alin | Saan |```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------\n",
    "#### Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- converts each row of the csv file into strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_chars(my_list):\n",
    "    \"\"\"\n",
    "    Remove the numbers in the beginning of the sentence.\n",
    "    Also removes unnecessary space characters in a sentence.\n",
    "    \n",
    "    my_list - list of sentences in a row\n",
    "    \"\"\"\n",
    "\n",
    "    for item in my_list:\n",
    "        if len(item) == 0 or item == \" \":\n",
    "            my_list.remove(item)\n",
    "\n",
    "        if re.match(\"^[0-9]\", item) is not None:\n",
    "            index = my_list.index(item)\n",
    "            tmp = item.lstrip('0123456789.- ')\n",
    "            my_list.remove(item)\n",
    "            my_list.insert(index, tmp)\n",
    "\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(input, output):\n",
    "    \"\"\"\n",
    "    Each row of the csf file contains 1 or more sentences.\n",
    "    This function visits each of the row then clean each \n",
    "    of the sentences in it.\n",
    "    \"\"\"\n",
    "\n",
    "    csv_f = csv.reader(input)\n",
    "    wr = csv.writer(output, delimiter=',', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    wr.writerow([\"Questions\", \"Category\"])\n",
    "\n",
    "    for row in csv_f:\n",
    "        for column in range(2, len(row)):\n",
    "            if row[column].count(\":\") == 0:\n",
    "                row_items = (row[column].split('\\n'))\n",
    "                row_items = remove_unwanted_chars(row_items)\n",
    "                wr = csv.writer(output, delimiter='\\n', quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow(row_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_wordpos_dict(file):\n",
    "    text = file.readlines()\n",
    "    array = list()\n",
    "    dict = {}\n",
    "    ctr = 0\n",
    "\n",
    "    for line in text:\n",
    "        data = line.split(\"\\t\")\n",
    "        if data[0] != \"?\":\n",
    "            word = data[0]\n",
    "            pos = data[len(data)-1]\n",
    "            # pos = get_tags(pos, 1)\n",
    "            dict[word] = pos.strip()\n",
    "        elif data[0] == '?':\n",
    "            array.append(dict)\n",
    "            dict = {}\n",
    "        ctr += 1\n",
    "\n",
    "    # print ctr\n",
    "    # print array\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(tag, level):\n",
    "    if level == 1:\n",
    "        tag = tag.split(\"-\")[0]\n",
    "    elif level == 2:\n",
    "        temp = tag.split(\"-\")[1]\n",
    "        tag = temp[:2]\n",
    "    elif level == 3:\n",
    "        temp = tag.split(\"-\")[1]\n",
    "        tag = temp[2:]\n",
    "\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    dict = {'NN': 0, 'PR': 0, 'DT': 0, 'LM': 0, 'CC': 0, 'VB': 0, 'JJ': 0,\n",
    "            'RB': 0, 'CD': 0, 'TS': 0}\n",
    "    temp = []\n",
    "    ctr = 0\n",
    "\n",
    "    for sentence in data:\n",
    "        for key in sentence:\n",
    "            ctr += 1\n",
    "            dict[sentence[key]] += 1\n",
    "\n",
    "        temp.append(dict)\n",
    "        dict = {'NN': 0, 'PR': 0, 'DT': 0, 'LM': 0, 'CC': 0, 'VB': 0,\n",
    "                'JJ': 0, 'RB': 0, 'CD': 0, 'TS': 0}\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_vector(file):\n",
    "    input_file = file\n",
    "    csv_f = csv.reader(input_file)\n",
    "\n",
    "    cat = []\n",
    "    column = 0\n",
    "    ctr = 0\n",
    "\n",
    "    category = {'entity': 1, 'abbreviation': 2, 'description': 3, 'human': 4,\n",
    "                'location': 5, 'numeric': 6}\n",
    "\n",
    "    for row in csv_f:\n",
    "        ctr += 1\n",
    "        if \"Questions\" not in row:\n",
    "            temp = []\n",
    "            for column in range(1, 2):\n",
    "                if(row[column] != \"Category\" and (row[column]) > 0):\n",
    "                    temp.append(category[row[column].lower()])\n",
    "            cat.append(temp)\n",
    "\n",
    "    input_file.close()\n",
    "\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_qmark(file):\n",
    "    text = file.readlines()\n",
    "\n",
    "    for line in text:\n",
    "        if line.count(\"?\") > 2:\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wh_question(file):\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    q_word_tags = {\n",
    "                    'alin': 1, 'saan': 2, 'ano': 3, 'kailan': 4, 'paano': 5,\n",
    "                    'sino': 6, 'bakit': 7\n",
    "                    }\n",
    "    q_words = {\n",
    "                'aling', 'alin-alin', 'alin-aling', 'saang', 'saan-saan',\n",
    "                'nasaan', 'nasaang', 'anong', 'anu-ano', 'anu-anong', 'inaano',\n",
    "                'paanong', 'papaano', 'papaanong', 'sinong', 'sinu-sino',\n",
    "                'sino-sinong', 'kailang'\n",
    "                }\n",
    "    vec = []\n",
    "\n",
    "    for row in reader:\n",
    "        sentence = row[0].split(\" \")\n",
    "        temp = []\n",
    "\n",
    "        for word in sentence:\n",
    "            if word.lower() in q_word_tags:\n",
    "                # print word.lower()\n",
    "                temp.append(q_word_tags[word.lower()])\n",
    "                vec.append(temp)\n",
    "                break\n",
    "            elif word.lower() in q_words:\n",
    "                for key in q_word_tags:\n",
    "                    if key in word.lower():\n",
    "                        temp.append(q_word_tags[key])\n",
    "                        vec.append(temp)\n",
    "                        break\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_word_data(file):\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    data = []\n",
    "\n",
    "    for row in reader:\n",
    "        # Escaping the first row because it only contains the column titles\n",
    "        if row is not ['Questions', 'Category']:\n",
    "            data.append(tokenizer.tokenize(row[0]))\n",
    "\n",
    "#     print(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------\n",
    "#### The Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    1. Preprocessing the raw data.\n",
    "    \"\"\"\n",
    "    # Input file reading and output file writing\n",
    "    input_file=open(os.path.abspath('files/Help a CS Student Graduate.csv'))\n",
    "    output_file=open(os.path.abspath('files/cleaning_output.csv'), 'w')\n",
    "    \n",
    "    # Cleaning\n",
    "    extract(input_file, output_file)\n",
    "    input_file.close()\n",
    "    output_file.close()\n",
    "    ########\n",
    "  \n",
    "    \"\"\"\n",
    "    2. DEBUGGING:\n",
    "    Checking the equality of the pos tags, wh-words and category gathered.\n",
    "    Total should be 3077.\n",
    "    \"\"\"\n",
    "    # Ouput file\n",
    "    dataset = 'files/dataset_pos.out'\n",
    "    \n",
    "    # Input file\n",
    "    labelled_data = 'files/labelled_data.csv'\n",
    "    \n",
    "    pos_data = to_wordpos_dict(open(os.path.abspath(dataset)))\n",
    "#     wh_vector = get_wh_question(open(os.path.abspath(labelled_data)))\n",
    "#     category = category_vector(open(os.path.abspath(labelled_data)))\n",
    "\n",
    "    print (\"Data Length: \", len(pos_data))\n",
    "#     print \"Wh_Question Length: \", len(wh_vector)\n",
    "#     print \"Category Length: \", len(category)\n",
    "    ###########\n",
    "\n",
    "    tokenize_word_data(open(os.path.abspath('files/labelled_data.csv')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Length:  3077\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
